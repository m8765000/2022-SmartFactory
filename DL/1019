http://103.60.126.183:8150/gidatalab

https://mediapipe.dev/

너비 높이  , bgr

opencv

파이썬 3.7.13버전 개발환경
pip install opencv-python

code . //vs코드열수있음

보기 > 명령팔레트 > 가상환경으로 실행

import cv2
print(cv2.__version__)
img = cv2.imread("./cv_basic/image/bts-01.jpg")
gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)
cv2.imshow("bts", img)
cv2.imshow("bts - gray",gray)
cv2.waitKey(0)
cv2.destroyAllWindows()
img

import cv2
print(cv2.__version__)
img = cv2.imread("./cv_basic/image/bts-01.jpg")

print("image shape: {} pixels".format(img.shape))

print("width: {} pixels".format(img.shape[1]))

print("height: {} pixels".format(img.shape[0]))
print("channels: {}".format(img.shape[2]))

cv2.imshow("bts", img)

gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)
cv2.imshow("bts", img)
cv2.imshow("bts - gray",gray)
cv2.imwrite("image/bts-1_gray.jpg", gray)

cv2.waitKey(0)

cv2.destroyAllWindows()

4.6.0
image shape: (394, 700, 3) pixels
width: 700 pixels
height: 394 pixels
channels: 3

opencv는 bgr , 세로 가로

도형을 그릴때 파라미터 사각형 점4개 원 점 반지름
import cv2

print(cv2.__version__)
img = cv2.imread("./cv_basic/image/bts-01.jpg")

print("image shape: {} pixels".format(img.shape))

print("width: {} pixels".format(img.shape[1]))

print("height: {} pixels".format(img.shape[0]))
print("channels: {}".format(img.shape[2]))

cv2.imshow("bts", img)

#높이 , 너비
img[100:150 , 50:100 ] = (0 , 0 , 255)
#cv2.rectangle(img, (좌 , 상 ), 우 , 하 ), (b, g, r), 선굵기
cv2.rectangle(img , (150 , 100 ), (200 , 150 ), ( 255 , 0 , 0 ), 5)
#cv2.circle(img, (좌 , 상 ), 반지름 , (b, g, r), 선굵기 ) # 1 모두 채움
cv2.circle(img , (275 , 125 ), 25 , ( 0 , 255 , 255 ), -1)
#cv2.line(img, (좌 , 상 ), 우 , 하 ), (b, g, r), 굵기
cv2.line(img , (350 , 100 ), (400 , 150 ), (255 , 0 , 0), 5)
#cv2.putText(img, '문자열 ', 시작위치 좌 , 상 ), font_style , 폰트크기 ,(b, g, r), 폰트굵기
cv2.putText(img , 'Hello~ BTS', (450 , 150 ), cv2.FONT_HERSHEY_SIMPLEX, 1 , (255 , 255 , 255 ), 4)
cv2.imshow("bts- draw", img)
cv2.waitKey(0)
cv2.destroyAllWindows()

움직이는 영상을 디텍팅
https://docs.opencv.org/4.6.0/d6/d00/tutorial_py_root.html

nomask_warning_pred.py
오늘
오후 2:53

kim kyongha님이 항목 1개를 업로드했습니다.
텍스트
nomask_warning_pred.py
from tensorflow.keras.models import load_model
from PIL import Image, ImageOps
import numpy as np

# Load the model
model = load_model('./models/keras_model.h5')

# 테스트 이미지를 저장할 변수의 타입과 shape 정의 
data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)

# 테스트 이미지 path 정의
image = Image.open('./image/nomask.jpg').convert('RGB')

# Teachable Machine의 기본 이미지 사이즈 정의 및 리사이즈
size = (224, 224)
image = ImageOps.fit(image, size, Image.ANTIALIAS)

# 이미지를 numpy array로 변경
image_array = np.asarray(image)

# Normalize the image
normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1

# 정규화한 이미지를 data 변수에 대입
data[0] = normalized_image_array

# labels.txt 파일 읽어오기
# load class_name
class_names=[]
with open("./models/labels.txt", "r") as f:
    print(f)
    for line in f:
        #print(line.strip())
        class_names.append(line)

# run the inference(추론)
prediction = model.predict(data)
index = np.argmax(prediction)
class_name = class_names[index]
confidence_score = prediction[0][index]

print("prediction : ", prediction)
print("np.argmax(prediction) : ", index)
print("Class: ", class_name)
print("Confidence Score: ", confidence_score)

/// 카메라로 인식 + 모델읽어서 분류하기
from configparser import Interpolation
from tensorflow.keras.models import load_model
from PIL import Image, ImageOps
import numpy as np
import cv2
video_cap = cv2.VideoCapture(0)

def videoReady():

    # 카메라 on 체크
    if not video_cap.isOpened:
        print('카메라 에러')
        exit(0)

    video_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    video_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    return video_cap

# Load the model
model = load_model("./keras_model.h5")

#labels.txt 파일 읽어오기
class_names=[]
with open("./labels.txt", "r") as f:
    print(f)
    for line in f:
        #print(line.strip())
        class_names.append(line)
        
# 비디오 표시
def videoDisplayDetection(image):
    cv2.imshow('video test', image)
    
    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
    size = (224, 224)
    frame_resized = cv2.resize(image, dsize=size, interpolation=cv2.INTER_AREA) #동영상처리 cv2.resize
    # Normalize the image
    normalized_image_array = (frame_resized.astype(np.float32) / 127.0) - 1
    # Load the image into the array
    data[0] = normalized_image_array

    
    return model.predict(data)

video_cap = videoReady()

while True:
    ret, frame = video_cap.read()
    
    if frame is None:
        print('### No more frame ###')
        video_cap.release()
        break;
    
             # run the inference
    prediction = videoDisplayDetection(frame)   
    index = np.argmax(prediction)
    class_name = class_names[index]
    confidence_score = prediction[0][index]

    print("Class: ", class_name)
    print("Confidence Score: ", confidence_score)
        
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break;



video_cap.release()
cv2.destroyAllWindows()


