데이터 프레임과 시리즈
pd.to_datetime(df['Born'])
데이터를 datetime 자료형으로 바꾸어줌 원래는 object
pd.to_datetime(df['Born'], format='%Y-%m-%d')
포맷은 YYYY - MM - DD, MM - DD - YYYY, YYYY/MM/DD


born_datetime = pd.to_datetime(df['Born'], format='%Y-%m-%d')
died_datetime = pd.to_datetime(df['Died'], format='%Y-%m-%d')
datetime으로바뀐 2개의 자료를 새로운 열로 추가
df['born_dt'],df['died_dt'] = (born_datetime, died_datetime)

과학자 삶의 시간 계산하기 (died_dt-born_dt)
df['age_days_dt'] = (df['died_dt'] - df['born_dt'])
df['age_days_dt']
iloc의 365로 나누어 대략 몇년 살았는지 알수있음 /30시 개월로 볼수있다.
df.iloc[0,-1]/365

df['born_dt'][0].year 0번째 년도

자료를 섞는법
df2=df.sample(frac=1)
df2.reset_index().iloc[:,1:]
데이터프레임 자체가 바뀐것이아님 덮어줘야(inplace) 바뀐게 저장이됨
df.drop(['Age', 'Occupation'], axis = 1, inplace=True) 

pickle 바이너리 형태로 저장된 데이터
df.to_pickle('scientists.pickle')
pd.read_pickle('scientists.pickle')
csv파일을 pickle로 변환후 그대로 가져올수있음

tsv csv에서 탭
df.to_csv('scientists_df.csv')
df.to_csv('scientists_df.csv', sep='\t') # seperate 탭을 기준으로 저장
불러오기
pd.read_csv('scientist.csv', sep='\t') separate를 탭으로 주기 불러올때
인덱스 지정하여 불러오기
pd.read_csv('scientists_df.csv', index_col =0 )
특정 컬럼을 인덱스로 지정하여 불러오기
pd.read_csv('scientists_df.csv', index_col ='Name' )
 
import seaborn as sns 안되면
conda uninstall scipy
conda install scipy
conda install seaborn

키는 범주로 사용할수없음 int를 범주로사용 나이

자료형 다루기
잘못 입력한 데이터 처리하기 to_numeric
raise 숫자로 변환할 수 있는 값이 있으면 오류 발생 (기본값)
coerce 숫자로 변환할 수 없는 값을 누락값으로 지정
ignore 아무 작업도 하지 않음

pd.to_numeric(tips['smoker'], errors = 'coerce') #. 'coerce', 'raise')

total_bill[[1,7,5]] = 'missing' 일부러 missing(ignore) 값을 넣어줌
total_bill
pd.to_numeric(total_bill, errors = 'coerce') #. 'coerce', 'raise') 누락값으로 변환

데이터 연결하기
그냥이어붙이는 용도로 사용된다.  위아래로 붙여짐 수직 axis = 0, axis =1 수평 
df1 = pd.read_csv('concat_1.csv')
df2 = pd.read_csv('concat_2.csv')
df3 = pd.read_csv('concat_3.csv')
row_concat = pd.concat([df1, df2, df3])

df2.columns = ['B','C','D','A']
df2.columns
pd.concat([df1,df2,df3])
다양한 방법으로 데이터 연결하기 ignore_index를 True로 지정하여 인덱스 정리
row_concat_i = pd.concat([df1,df2,df3], ignore_index=True)
print(row_concat_i)

공통 열과 공통 인덱스만 연결하기 join 'A','C'
print(pd.concat([df1, df3], join ='inner'))

데이터 연결 전용 메소드 merge 사용하기
person = pd.read_csv('data/data/survey_person.csv')
site = pd.read_csv('data/data/survey_site.csv')
visited = pd.read_csv('data/data/survey_visited.csv')
survey = pd.read_csv('data/data/survey_survey.csv')

연결하려는 열 이름이 다른경우 left_on, right_on 옵션 사용
ps_merge = person.merge(survey, left_on = 'ident', right_on = 'person')
print(ps_merge)

ident_x visited 
ident_y person
하나의 데이터로 합쳐서 중복이 되어서 왼쪽과 오른쪽에 있는것을 지정해서 이름을 자동으로 지어줌

누락값 처리하기
 np.NaN == np.Nan 은 값은값이 아니다.

survey.isnull().sum() 
visited.notnull().sum()
visited.info() 편하게 null값을 이렇게 확인 할 수 있다.

ebola = pd.read_csv('data/data/country_timeseries.csv')
ebola.head()
case_ 감염자 수 Deaths_ 사망자수
ebola.countnt() 누락값 개수 확인 누락값이 아닌 값의 개수가 나온다.

shape[0]에 전체 행 개수 - 값의 개수 = 누락값의 개수 (브로드캐스팅)
num_rows = ebola.shape[0]
num_missing = num_rows - ebola.count()
num_missing

누락값 개수 확인 - count_nonzero(), isnull(), value_counts()
-count_nonzero() 배열에서 0(False)이 아닌 값의 개수 확인
import numpy as np
print(np.count_nonzero(ebola.isnull()))
print(np.count_nonzero(ebola['Cases_Guinea'].isnull()))

print(ebola['Cases_Guinea'].value_counts(dropna=False))
출력되는 NaN값은 다 다르지만 NaN의 개수가 나온다.

누락값 변경하기 – fill_na()

앞의갚을 기준으로 NaN의 값을 바꿈

ebola.fillna(method='ffill').fillna(method='bfill')
뒤의값을 기준으로 바꿔줌


누락값 변경하기 – interpolate()
- 누락값 양쪽에 있는 값을 이용하여 중간값을 구한 다음 변경
ebola.interpolate()

누락값 삭제하기 – drop_na()
- 누락값이 포함된 데이터 삭제
ebola.dropna()

깔끔한 데이터
데이터를 유지시키면서 컬럼을 행으로 정리해서 새로운 데이터를 만든다.
열의 데이터를 행으로 정리 : melt()
import pandas as pd
pew = pd.read_csv('data/pew.csv')
print(pew)
id_vars 변형시키지 않을 데이터
pd.melt(pew, id_vars = 'religion', var_name = 'income', value_name='count')

빌보드 차트 데이터 피벗 (2개 이상의 열 고정 / 나머지 행 변환)
billboard = pd.read_csv('data/data/billboard.csv')
print(billboard.shape)
billboard.columns

